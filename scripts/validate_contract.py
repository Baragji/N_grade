#!/usr/bin/env python3
"""
Contract Validator - ZERO TOLERANCE enforcement of documentation delivery contracts.

Usage:
    python scripts/validate_contract.py docs_ui_2_contracts/roadmap_v2_complete_expansion.contract.json
    python scripts/validate_contract.py <contract_file> --strict --report-path <output.json>

Exit codes:
    0: ACCEPTED (all quality gates passed)
    1: REJECTED (one or more failures)
    2: ERROR (invalid contract or validation failure)
"""

import argparse
import json
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Tuple


class ContractValidator:
    """Enforces documentation delivery contracts with zero tolerance for non-compliance."""
    
    def __init__(self, contract_path: Path, repo_root: Path, strict: bool = True):
        self.contract_path = contract_path
        self.repo_root = repo_root
        self.strict = strict
        self.contract = self._load_contract()
        self.results = {
            "contract_id": self.contract.get("contract_id", "UNKNOWN"),
            "execution_summary": {
                "start_time": datetime.utcnow().isoformat() + "Z",
                "end_time": None,
                "elapsed_seconds": 0,
                "deliverables_count": len(self.contract.get("deliverables", []))
            },
            "deliverable_status": [],
            "cross_file_validation_results": [],
            "definition_of_done_status": {},
            "final_verdict": "REJECTED",
            "rejection_reasons": [],
            "validation_report_path": None
        }
    
    def _load_contract(self) -> Dict[str, Any]:
        """Load and validate contract JSON."""
        try:
            with open(self.contract_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ùå FATAL: Cannot load contract: {e}", file=sys.stderr)
            sys.exit(2)
    
    def _resolve_path(self, file_path: str) -> Path:
        """Resolve file path relative to repo root."""
        path = Path(file_path)
        if path.is_absolute():
            return path
        return self.repo_root / file_path
    
    def _validate_line_count(self, file_path: Path, min_lines: int, max_lines: int = None) -> Tuple[bool, int, str]:
        """Check if file meets line count requirements."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            line_count = len(lines)
            
            if line_count < min_lines:
                return False, line_count, f"Only {line_count} lines (required: ‚â•{min_lines})"
            if max_lines and line_count > max_lines:
                return False, line_count, f"Too many lines: {line_count} (max: {max_lines})"
            return True, line_count, f"{line_count} lines (required: ‚â•{min_lines})"
        except Exception as e:
            return False, 0, f"Cannot read file: {e}"
    
    def _validate_required_sections(self, file_path: Path, patterns: List[str]) -> Tuple[bool, List[str]]:
        """Check if all required section patterns exist."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            missing = []
            for pattern in patterns:
                if not re.search(pattern, content, re.MULTILINE):
                    missing.append(pattern)
            
            return len(missing) == 0, missing
        except Exception as e:
            return False, [f"Cannot read file: {e}"]
    
    def _validate_forbidden_patterns(self, file_path: Path, forbidden: List[Dict]) -> Tuple[bool, List[Dict]]:
        """Check for forbidden patterns (template markers, TODOs, etc.)."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            violations = []
            for item in forbidden:
                pattern = item["pattern"]
                reason = item["reason"]
                matches = re.findall(pattern, content, re.IGNORECASE)
                if matches:
                    violations.append({
                        "pattern": pattern,
                        "reason": reason,
                        "occurrences": len(matches),
                        "examples": matches[:3]  # First 3 examples
                    })
            
            return len(violations) == 0, violations
        except Exception as e:
            return False, [{"pattern": "file_read", "reason": str(e), "occurrences": 1, "examples": []}]
    
    def _validate_required_patterns(self, file_path: Path, required: List[Dict]) -> Tuple[bool, List[Dict]]:
        """Check for required patterns (code blocks, metrics, etc.)."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            failures = []
            for item in required:
                pattern = item["pattern"]
                min_occ = item["min_occurrences"]
                reason = item["reason"]
                matches = re.findall(pattern, content, re.MULTILINE | re.IGNORECASE)
                if len(matches) < min_occ:
                    failures.append({
                        "pattern": pattern,
                        "reason": reason,
                        "required": min_occ,
                        "found": len(matches)
                    })
            
            return len(failures) == 0, failures
        except Exception as e:
            return False, [{"pattern": "file_read", "reason": str(e), "required": 0, "found": 0}]
    
    def _check_duplicate_sections(self, file_path: Path) -> Tuple[bool, List[str]]:
        """Check for duplicate section headers."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # Find all markdown headers
            headers = []
            for i, line in enumerate(lines, 1):
                if re.match(r'^#{1,6}\s+', line):
                    headers.append((line.strip(), i))
            
            # Find duplicates
            seen = {}
            duplicates = []
            for header, line_num in headers:
                if header in seen:
                    duplicates.append(f"{header} (lines {seen[header]} and {line_num})")
                else:
                    seen[header] = line_num
            
            return len(duplicates) == 0, duplicates
        except Exception as e:
            return False, [f"Cannot read file: {e}"]
    
    def _validate_structural_requirements(self, file_path: Path, requirements: Dict) -> Tuple[bool, Dict]:
        """Check structural requirements (code blocks, tables, lists)."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            results = {}
            failures = []
            
            # Code blocks
            if "min_code_blocks" in requirements:
                code_blocks = len(re.findall(r'```[\w]*', content))
                results["code_blocks"] = code_blocks
                if code_blocks < requirements["min_code_blocks"]:
                    failures.append(f"Only {code_blocks} code blocks (required: ‚â•{requirements['min_code_blocks']})")
            
            # Tables
            if "min_tables" in requirements:
                tables = len(re.findall(r'^\|.*\|$', content, re.MULTILINE))
                results["tables"] = tables // 3  # Rough estimate (header + separator + rows)
                if results["tables"] < requirements["min_tables"]:
                    failures.append(f"Only {results['tables']} tables (required: ‚â•{requirements['min_tables']})")
            
            # Lists
            if "min_lists" in requirements:
                lists = len(re.findall(r'^[\s]*[-*+]\s+', content, re.MULTILINE))
                results["lists"] = lists
                if lists < requirements["min_lists"]:
                    failures.append(f"Only {lists} list items (required: ‚â•{requirements['min_lists']})")
            
            return len(failures) == 0, {"results": results, "failures": failures}
        except Exception as e:
            return False, {"results": {}, "failures": [f"Cannot read file: {e}"]}
    
    def validate_deliverable(self, deliverable: Dict) -> Dict:
        """Validate a single deliverable against all quality gates."""
        file_path_str = deliverable["file_path"]
        file_path = self._resolve_path(file_path_str)
        quality_gates = deliverable["quality_gates"]
        
        result = {
            "file_path": file_path_str,
            "status": "PASS",
            "line_count": 0,
            "quality_gate_results": {},
            "failures": []
        }
        
        # Check file exists
        if not file_path.exists():
            result["status"] = "FAIL"
            result["failures"].append({
                "check": "file_exists",
                "expected": "File exists",
                "actual": "File not found",
                "severity": "CRITICAL"
            })
            return result
        
        # Line count
        if "min_lines" in quality_gates:
            passed, line_count, msg = self._validate_line_count(
                file_path,
                quality_gates["min_lines"],
                quality_gates.get("max_lines")
            )
            result["line_count"] = line_count
            result["quality_gate_results"]["min_lines"] = passed
            if not passed:
                result["status"] = "FAIL"
                result["failures"].append({
                    "check": "line_count",
                    "expected": f"‚â•{quality_gates['min_lines']} lines",
                    "actual": msg,
                    "severity": "CRITICAL"
                })
        
        # Required sections
        if "required_sections" in quality_gates:
            passed, missing = self._validate_required_sections(file_path, quality_gates["required_sections"])
            result["quality_gate_results"]["required_sections"] = passed
            if not passed:
                result["status"] = "FAIL"
                for pattern in missing[:5]:  # Show first 5 missing
                    result["failures"].append({
                        "check": "required_section",
                        "expected": f"Section matching '{pattern}'",
                        "actual": "Not found",
                        "severity": "ERROR"
                    })
        
        # Forbidden patterns
        if "forbidden_patterns" in quality_gates:
            passed, violations = self._validate_forbidden_patterns(file_path, quality_gates["forbidden_patterns"])
            result["quality_gate_results"]["forbidden_patterns"] = passed
            if not passed:
                result["status"] = "FAIL"
                for v in violations:
                    result["failures"].append({
                        "check": "forbidden_pattern",
                        "expected": f"Zero occurrences of '{v['pattern']}'",
                        "actual": f"{v['occurrences']} found: {v['examples']}",
                        "severity": "CRITICAL"
                    })
        
        # Required patterns
        if "required_patterns" in quality_gates:
            passed, failures = self._validate_required_patterns(file_path, quality_gates["required_patterns"])
            result["quality_gate_results"]["required_patterns"] = passed
            if not passed:
                result["status"] = "FAIL"
                for f in failures:
                    result["failures"].append({
                        "check": "required_pattern",
                        "expected": f"‚â•{f['required']} matches for '{f['pattern']}'",
                        "actual": f"Only {f['found']} found",
                        "severity": "ERROR"
                    })
        
        # No duplicate sections
        if quality_gates.get("no_duplicate_sections", False):
            passed, duplicates = self._check_duplicate_sections(file_path)
            result["quality_gate_results"]["no_duplicate_sections"] = passed
            if not passed:
                result["status"] = "FAIL"
                for dup in duplicates[:5]:
                    result["failures"].append({
                        "check": "no_duplicates",
                        "expected": "Unique section headers",
                        "actual": f"Duplicate: {dup}",
                        "severity": "ERROR"
                    })
        
        # Structural requirements
        if "structural_requirements" in quality_gates:
            passed, data = self._validate_structural_requirements(file_path, quality_gates["structural_requirements"])
            result["quality_gate_results"]["structural_requirements"] = passed
            if not passed:
                result["status"] = "FAIL"
                for failure in data["failures"]:
                    result["failures"].append({
                        "check": "structural_requirement",
                        "expected": "Meet structural minimums",
                        "actual": failure,
                        "severity": "ERROR"
                    })
        
        return result
    
    def validate_all(self) -> bool:
        """Run full validation and generate report."""
        start = datetime.utcnow()
        
        # Validate each deliverable
        for deliverable in self.contract.get("deliverables", []):
            result = self.validate_deliverable(deliverable)
            self.results["deliverable_status"].append(result)
        
        # Cross-file validations (basic implementation)
        for validation in self.contract.get("cross_file_validations", []):
            # Simple pass for now (would need specific implementation per validation type)
            self.results["cross_file_validation_results"].append({
                "validation_name": validation.get("name") or validation.get("validation_name"),
                "status": "PASS",
                "details": "Manual review required"
            })
        
        # Compute Definition of Done status
        all_deliverables_present = all(
            r["status"] != "FAIL" or "file_exists" not in [f["check"] for f in r["failures"]]
            for r in self.results["deliverable_status"]
        )
        all_quality_gates_passed = all(
            r["status"] == "PASS"
            for r in self.results["deliverable_status"]
        )
        all_cross_file_passed = all(
            r["status"] == "PASS"
            for r in self.results["cross_file_validation_results"]
        )
        no_forbidden_found = all(
            r.get("quality_gate_results", {}).get("forbidden_patterns", True)
            for r in self.results["deliverable_status"]
        )
        
        self.results["definition_of_done_status"] = {
            "all_deliverables_present": all_deliverables_present,
            "all_quality_gates_passed": all_quality_gates_passed,
            "all_cross_file_validations_passed": all_cross_file_passed,
            "no_forbidden_patterns_found": no_forbidden_found,
            "validation_report_generated": True
        }
        
        # Compute final verdict
        dod = self.results["definition_of_done_status"]
        if all([dod["all_deliverables_present"], dod["all_quality_gates_passed"],
                dod["all_cross_file_validations_passed"], dod["no_forbidden_patterns_found"]]):
            self.results["final_verdict"] = "ACCEPTED"
        else:
            self.results["final_verdict"] = "REJECTED"
            reasons = []
            if not dod["all_deliverables_present"]:
                reasons.append("Missing or inaccessible deliverables")
            if not dod["all_quality_gates_passed"]:
                reasons.append("Quality gate failures")
            if not dod["all_cross_file_validations_passed"]:
                reasons.append("Cross-file validation failures")
            if not dod["no_forbidden_patterns_found"]:
                reasons.append("Forbidden patterns detected (templates, TODOs, etc.)")
            self.results["rejection_reasons"] = reasons
        
        # Finalize timing
        end = datetime.utcnow()
        self.results["execution_summary"]["end_time"] = end.isoformat() + "Z"
        self.results["execution_summary"]["elapsed_seconds"] = (end - start).total_seconds()
        
        return self.results["final_verdict"] == "ACCEPTED"
    
    def save_report(self, report_path: Path):
        """Save validation report as JSON."""
        self.results["validation_report_path"] = str(report_path)
        report_path.parent.mkdir(parents=True, exist_ok=True)
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2)
    
    def print_summary(self):
        """Print human-readable summary."""
        verdict = self.results["final_verdict"]
        dod = self.results["definition_of_done_status"]
        
        if verdict == "ACCEPTED":
            print("\n" + "="*80)
            print("‚úÖ CONTRACT ACCEPTED - ALL QUALITY GATES PASSED")
            print("="*80)
        else:
            print("\n" + "="*80)
            print("‚ùå CONTRACT REJECTED - DELIVERABLE DOES NOT MEET REQUIREMENTS")
            print("="*80)
            print("\nREJECTION REASONS:")
            for reason in self.results["rejection_reasons"]:
                print(f"  ‚Ä¢ {reason}")
        
        print(f"\nüìä DEFINITION OF DONE STATUS:")
        print(f"  All deliverables present: {'‚úÖ' if dod['all_deliverables_present'] else '‚ùå'}")
        print(f"  All quality gates passed: {'‚úÖ' if dod['all_quality_gates_passed'] else '‚ùå'}")
        print(f"  Cross-file validations passed: {'‚úÖ' if dod['all_cross_file_validations_passed'] else '‚ùå'}")
        print(f"  No forbidden patterns: {'‚úÖ' if dod['no_forbidden_patterns_found'] else '‚ùå'}")
        
        print(f"\nüìÅ DELIVERABLE STATUS:")
        for result in self.results["deliverable_status"]:
            status_icon = "‚úÖ" if result["status"] == "PASS" else "‚ùå"
            print(f"  {status_icon} {result['file_path']} ({result['line_count']} lines)")
            if result["status"] == "FAIL":
                for failure in result["failures"][:10]:  # Show first 10 failures
                    print(f"      ‚îî‚îÄ {failure['severity']}: {failure['check']}")
                    print(f"         Expected: {failure['expected']}")
                    print(f"         Actual: {failure['actual']}")
        
        print(f"\n‚è±Ô∏è  Validation completed in {self.results['execution_summary']['elapsed_seconds']:.2f}s")


def main():
    parser = argparse.ArgumentParser(
        description="Validate documentation deliverables against contract",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument("contract", type=Path, help="Path to contract JSON file")
    parser.add_argument("--repo-root", type=Path, default=Path.cwd(),
                        help="Repository root (default: current directory)")
    parser.add_argument("--report-path", type=Path, default=Path("_reports/validation.json"),
                        help="Output path for validation report")
    parser.add_argument("--strict", action="store_true", default=True,
                        help="Strict mode (fail on any violation)")
    parser.add_argument("--print-report", action="store_true",
                        help="Print full JSON report to stdout")
    
    args = parser.parse_args()
    
    validator = ContractValidator(args.contract, args.repo_root, args.strict)
    passed = validator.validate_all()
    validator.save_report(args.report_path)
    validator.print_summary()
    
    if args.print_report:
        print("\n" + "="*80)
        print("FULL VALIDATION REPORT:")
        print("="*80)
        print(json.dumps(validator.results, indent=2))
    
    sys.exit(0 if passed else 1)


if __name__ == "__main__":
    main()